{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras import (\n",
    "    Input,\n",
    "    Sequential,\n",
    "    layers,\n",
    "    models,\n",
    "    callbacks,\n",
    "    utils,\n",
    "    metrics,\n",
    "    optimizers,\n",
    ")\n",
    "from conlanger.models.WGANGP import WGANGP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load(\"./data/language_phonemes.npz\", allow_pickle=True)\n",
    "language_phonemes_selected = data[\"language_phonemes_selected\"]\n",
    "language_names_selected = data[\"language_names_selected\"]\n",
    "\n",
    "# pad to 32x32\n",
    "X = language_phonemes_selected.copy()\n",
    "X = np.hstack([X, np.full((X.shape[0], 32 - X.shape[1], X.shape[2]), 0)])\n",
    "X = np.dstack([X, np.full((X.shape[0], X.shape[1], 32 - X.shape[2]), 0)])\n",
    "X = np.expand_dims(X, axis=3)\n",
    "\n",
    "assert language_phonemes_selected.shape[0] == language_names_selected.shape[0]\n",
    "(language_phonemes_selected.shape, language_names_selected.shape, X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = 32\n",
    "CHANNELS = 1\n",
    "BATCH_SIZE = 128\n",
    "NUM_FEATURES = 64\n",
    "Z_DIM = 32 * 32\n",
    "LEARNING_RATE = 0.0002\n",
    "ADAM_BETA_1 = 0.5\n",
    "ADAM_BETA_2 = 0.999\n",
    "EPOCHS = 50\n",
    "CRITIC_STEPS = 3\n",
    "GP_WEIGHT = 10.0\n",
    "LOAD_MODEL = False\n",
    "ADAM_BETA_1 = 0.5\n",
    "ADAM_BETA_2 = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape = X.shape[1:]\n",
    "width = shape[0]\n",
    "\n",
    "print(shape)\n",
    "\n",
    "critic = Sequential(\n",
    "    [\n",
    "        Input(shape=shape),\n",
    "        layers.Conv2D(IMAGE_SIZE, kernel_size=2, strides=2, padding=\"same\"),\n",
    "        layers.LeakyReLU(0.2),\n",
    "        layers.Conv2D(IMAGE_SIZE * 2, kernel_size=2, strides=2, padding=\"same\"),\n",
    "        layers.LeakyReLU(),\n",
    "        layers.Dropout(0.3),\n",
    "        layers.Conv2D(IMAGE_SIZE * 4, kernel_size=2, strides=2, padding=\"same\"),\n",
    "        layers.LeakyReLU(0.2),\n",
    "        layers.Dropout(0.3),\n",
    "        layers.Conv2D(IMAGE_SIZE * 8, kernel_size=2, strides=2, padding=\"same\"),\n",
    "        layers.LeakyReLU(0.2),\n",
    "        layers.Dropout(0.3),\n",
    "        layers.Conv2D(IMAGE_SIZE * 16, kernel_size=2, strides=1, padding=\"same\"),\n",
    "        layers.LeakyReLU(0.2),\n",
    "        layers.Dropout(0.3),\n",
    "        layers.Conv2D(1, kernel_size=2, strides=1, padding=\"valid\"),\n",
    "        layers.Flatten(),\n",
    "    ],\n",
    "    name=\"critic\",\n",
    ")\n",
    "critic.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = Sequential(\n",
    "    [\n",
    "        Input(shape=(Z_DIM,)),\n",
    "        layers.Reshape((1, 1, Z_DIM)),\n",
    "        layers.Conv2DTranspose(\n",
    "            256, kernel_size=4, strides=1, padding=\"valid\", use_bias=False\n",
    "        ),\n",
    "        layers.Dropout(0.2),\n",
    "        layers.Conv2D(\n",
    "            256, kernel_size=3, strides=1, padding=\"same\", use_bias=False\n",
    "        ),\n",
    "        layers.BatchNormalization(momentum=0.9),\n",
    "        layers.LeakyReLU(0.2),\n",
    "        layers.Conv2DTranspose(\n",
    "            128, kernel_size=4, strides=2, padding=\"same\", use_bias=False\n",
    "        ),\n",
    "        layers.Dropout(0.2),\n",
    "        layers.Conv2D(\n",
    "            128, kernel_size=3, strides=1, padding=\"same\", use_bias=False\n",
    "        ),\n",
    "        layers.BatchNormalization(momentum=0.9),\n",
    "        layers.LeakyReLU(0.2),\n",
    "        layers.Conv2DTranspose(\n",
    "            64, kernel_size=4, strides=2, padding=\"same\", use_bias=False\n",
    "        ),\n",
    "        layers.Dropout(0.2),\n",
    "        layers.Conv2D(\n",
    "            64, kernel_size=3, strides=1, padding=\"same\", use_bias=False\n",
    "        ),\n",
    "        layers.BatchNormalization(momentum=0.9),\n",
    "        layers.LeakyReLU(0.2),\n",
    "        layers.Conv2DTranspose(\n",
    "            32, kernel_size=4, strides=2, padding=\"same\", use_bias=False\n",
    "        ),\n",
    "        layers.Dropout(0.2),\n",
    "        layers.Conv2D(32, kernel_size=3, strides=1, padding=\"same\", use_bias=False),\n",
    "        layers.BatchNormalization(momentum=0.9),\n",
    "        layers.LeakyReLU(0.2),\n",
    "        layers.Conv2DTranspose(\n",
    "            32, kernel_size=4, strides=1, padding=\"same\", use_bias=False\n",
    "        ),\n",
    "        layers.Dropout(0.2),\n",
    "        layers.Conv2D(32, kernel_size=3, strides=1, padding=\"same\", use_bias=False),\n",
    "        layers.BatchNormalization(momentum=0.9),\n",
    "        layers.LeakyReLU(0.2),\n",
    "        layers.Conv2DTranspose(\n",
    "            CHANNELS, kernel_size=4, strides=1, padding=\"same\", activation=\"tanh\"\n",
    "        ),\n",
    "    ],\n",
    "    name=\"generator\",\n",
    ")\n",
    "generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a GAN\n",
    "wgangp = WGANGP(\n",
    "    critic=critic,\n",
    "    generator=generator,\n",
    "    latent_dim=Z_DIM,\n",
    "    critic_steps=CRITIC_STEPS,\n",
    "    gp_weight=GP_WEIGHT,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the GAN\n",
    "wgangp.compile(\n",
    "    c_optimizer=optimizers.Adam(\n",
    "        learning_rate=LEARNING_RATE, beta_1=ADAM_BETA_1, beta_2=ADAM_BETA_2\n",
    "    ),\n",
    "    g_optimizer=optimizers.Adam(\n",
    "        learning_rate=LEARNING_RATE, beta_1=ADAM_BETA_1, beta_2=ADAM_BETA_2\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "class ImageGenerator(callbacks.Callback):\n",
    "    def __init__(self, num_img, latent_dim):\n",
    "        self.num_img = num_img\n",
    "        self.latent_dim = latent_dim\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        random_latent_vectors = tf.random.normal(\n",
    "            shape=(self.num_img, self.latent_dim)\n",
    "        )\n",
    "        generated_images = self.model.generator(random_latent_vectors)\n",
    "        generated_images = generated_images * 127.5 + 127.5\n",
    "        generated_images = generated_images.numpy()\n",
    "        plt.figure(figsize=(IMAGE_SIZE, IMAGE_SIZE))\n",
    "\n",
    "        for i in range(10):\n",
    "            _ = plt.subplot(1, 10, i + 1)\n",
    "            plt.imshow(generated_images[i].astype(\"float32\"), cmap=\"copper_r\")\n",
    "            plt.axis(\"off\")\n",
    "        \n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices(X)\n",
    "\n",
    "wgangp.fit(\n",
    "    dataset.repeat(),\n",
    "    epochs=EPOCHS,\n",
    "    steps_per_epoch=3,\n",
    "    callbacks=[\n",
    "        ImageGenerator(num_img=10, latent_dim=Z_DIM),\n",
    "    ],\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conlanger",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
