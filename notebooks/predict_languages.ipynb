{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2949, 29, 24), (2949,))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.load(\"./data/language_phonemes_all.npz\", allow_pickle=True)\n",
    "language_phonemes_all = data[\"language_phonemes_all\"]\n",
    "language_names_all = data[\"language_names_all\"]\n",
    "\n",
    "assert language_phonemes_all.shape[0] == language_names_all.shape[0]\n",
    "language_phonemes_all.shape, language_names_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Iron Ossetic', 10), ('Dutch', 9), ('Basque', 6), ('Laz', 6), ('Northeastern Thai', 5)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((342,), (342, 29, 24), (29, 24), 2740)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_names, unique_names_count = np.unique(language_names_all, return_counts=True)\n",
    "multiple_samples = unique_names[unique_names_count > 1]\n",
    "\n",
    "count_sort_idx_desc = np.argsort(-unique_names_count)\n",
    "\n",
    "most_common_languages = list(\n",
    "    zip(unique_names[count_sort_idx_desc], unique_names_count[count_sort_idx_desc])\n",
    ")\n",
    "\n",
    "print(most_common_languages[0:5])\n",
    "\n",
    "X = language_phonemes_all[np.in1d(language_names_all, multiple_samples)]\n",
    "y = language_names_all[np.in1d(language_names_all, multiple_samples)]\n",
    "\n",
    "sample_shape = X[0].shape\n",
    "num_classes = len(unique_names)\n",
    "\n",
    "y.shape, X.shape, sample_shape, num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((208, 2740), (134, 2740))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.39, random_state=33)\n",
    "\n",
    "y_train = to_categorical(y_train, num_classes)\n",
    "y_test = to_categorical(y_test, num_classes)\n",
    "\n",
    "y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(\n",
    "    X[0],\n",
    "    cmap=plt.get_cmap(\"copper_r\"),\n",
    ")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape=(29, 24)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"language_model\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"language_model\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">696</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">89,216</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2740</span>)           │       <span style=\"color: #00af00; text-decoration-color: #00af00\">353,460</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m696\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m89,216\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2740\u001b[0m)           │       \u001b[38;5;34m353,460\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">442,676</span> (1.69 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m442,676\u001b[0m (1.69 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">442,676</span> (1.69 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m442,676\u001b[0m (1.69 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from keras import Input, Sequential, layers\n",
    "\n",
    "# Create network architecture\n",
    "\n",
    "input_shape = X[0].shape\n",
    "\n",
    "print(f\"shape={input_shape}\")\n",
    "\n",
    "model = Sequential(\n",
    "    [\n",
    "        Input(shape=input_shape),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(128, activation=\"relu\"),\n",
    "        layers.Dropout(0.2),\n",
    "        layers.Dense(num_classes, activation=\"softmax\"),\n",
    "    ],\n",
    "    name=\"language_model\"\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compilation\n",
    "\n",
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(208, 29, 24)\n",
      "(208, 2740)\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.0000e+00 - loss: 7.9222\n",
      "Epoch 2/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.0030 - loss: 7.8213    \n",
      "Epoch 3/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.0181 - loss: 7.6354 \n",
      "Epoch 4/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.0120 - loss: 7.3323    \n",
      "Epoch 5/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0393 - loss: 6.8312\n",
      "Epoch 6/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.0258 - loss: 6.1446\n",
      "Epoch 7/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.0113 - loss: 5.4407    \n",
      "Epoch 8/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0246 - loss: 4.9323\n",
      "Epoch 9/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0352 - loss: 4.7984 \n",
      "Epoch 10/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0249 - loss: 4.7389\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x10bddb530>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "\n",
    "\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0380 - loss: 5.1252  \n",
      "Classes: 2740\n",
      "Samples per language: 13.17\n",
      "Random guess probability: 0.00036\n",
      "Most common language probability: 0.00365\n",
      "5 most common language probability: 0.01314\n",
      "Model accuracy: 0.03731\n"
     ]
    }
   ],
   "source": [
    "# accuracy doesn't look great, but it's not bad considering there\n",
    "# is only one training sample of many of the languages and the\n",
    "# number of classes is in the thousands\n",
    "\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "\n",
    "print(f\"Classes: {num_classes}\")\n",
    "print(f\"Samples per language: {num_classes / len(y_train):.2f}\")\n",
    "print(f\"Random guess probability: {1 / num_classes:.5f}\")\n",
    "print(\n",
    "    f\"Most common language probability: {most_common_languages[0][1] / num_classes:.5f}\"\n",
    ")\n",
    "print(\n",
    "    f\"5 most common language probability: {np.sum([y for _, y in most_common_languages[0:5]]) / num_classes:.5f}\"\n",
    ")\n",
    "print(f\"Model accuracy: {test_acc:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step\n",
      "Correct preditions: 4.0%\n",
      "Predicted from top 5: 100.0%\n"
     ]
    }
   ],
   "source": [
    "# The predictions are heavily skewed towards languages that appear multiple\n",
    "# times in the dataset (to be expected really). So, to genrate synthetic examples\n",
    "# that don't just copy the most common languages, it'll probably be necessary to \n",
    "# limit the trainling data for synthetic data genertion to 1 example or a small \n",
    "# number of examples per language.\n",
    "\n",
    "num_samples = 50\n",
    "top_n_languages = set([name for name, _ in most_common_languages[0:5]])\n",
    "\n",
    "predictions = label_encoder.inverse_transform(\n",
    "    model.predict(X_test[0:num_samples]).argmax(axis=-1)\n",
    ")\n",
    "actual = label_encoder.inverse_transform(y_test[0:num_samples].argmax(axis=-1))\n",
    "\n",
    "correct_predictions = sum([1 if p == a else 0 for p, a in zip(predictions, actual)])\n",
    "\n",
    "predicted_from_common = sum([1 if p in top_n_languages else 0 for p in predictions])\n",
    "\n",
    "print(f\"Correct preditions: {correct_predictions / len(predictions) * 100}%\")\n",
    "print(f\"Predicted from top 5: {predicted_from_common / len(predictions) * 100}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wals",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
